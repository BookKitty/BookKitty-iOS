import AVFoundation
import BookMatchAPI
import BookMatchCore
import BookMatchStrategy
import CoreFoundation
import CoreML
import RxSwift
import UIKit
import Vision

@_exported import struct BookMatchCore.OwnedBook

/// ë„ì„œ `ë§¤ì¹­` ê¸°ëŠ¥ì˜ í•µì‹¬ ëª¨ë“ˆì…ë‹ˆë‹¤.
/// ì‚¬ìš©ìì˜ ìš”ì²­ì„ ì²˜ë¦¬í•˜ê³ , ë„ì„œ ê²€ìƒ‰, `ë§¤ì¹­` ê¸°ëŠ¥ì„ ì¡°ìœ¨í•©ë‹ˆë‹¤.
public final class BookMatchKit: @preconcurrency BookMatchable {
    // MARK: - Properties

    // MARK: - Private

    private let imageStrategy = VisionImageStrategy()
    private let apiClient: APIClientProtocol
    private let disposeBag = DisposeBag()

    // MARK: - Lifecycle

    public init(
        naverClientId: String,
        naverClientSecret: String
    ) {
        let config = APIConfiguration(
            naverClientId: naverClientId,
            naverClientSecret: naverClientSecret,
            openAIApiKey: ""
        )

        apiClient = DefaultAPIClient(configuration: config)
    }

    // MARK: - Functions

    // MARK: - Public

    /// `OCRë¡œ ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë°ì´í„°ì™€ ì´ë¯¸ì§€`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ë„ì„œë¥¼ `ë§¤ì¹­`í•©ë‹ˆë‹¤.
    ///
    /// - Parameters:
    ///   - image: ë„ì„œ í‘œì§€ ì´ë¯¸ì§€
    /// - Returns: ë§¤ì¹­ëœ ë„ì„œ ì •ë³´ ë˜ëŠ” nil
    /// - Throws: ì´ˆê¸° ë‹¨ì–´ë¶€í„° ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ ì•Šì„ ë•Œ
    @MainActor
    public func matchBook(image: UIImage) -> Single<BookItem?> {
        print("ğŸ›  matchBook(image:) ì‹¤í–‰ë¨") // âœ… matchBook í•¨ìˆ˜ ì‹¤í–‰ í™•ì¸

        let extractStream: Single<[String]> = Single.deferred { [weak self] in
            guard let self else {
                return .just([])
            }
            print("ğŸ“Œ OCR ì‹¤í–‰ ì‹œë„") // âœ… OCR ì‹¤í–‰ ì§ì „ í™•ì¸
            return extractText(from: image)
                .do(onSuccess: { text in
                    print("ğŸ“‘ OCR ì¶”ì¶œ ê²°ê³¼: \(text)")
                }, onError: { error in
                    print("âš ï¸ OCR ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: \(error.localizedDescription)")
                })
        }

        let searchBook = { [weak self] (textData: [String]) -> Single<[BookItem]> in
            guard let self else {
                return .just([])
            }

            print("ğŸ” ì±… ê²€ìƒ‰ ì‹œì‘: \(textData)")
            return fetchSearchResults(from: textData)
                .do(onSuccess: { books in
                    print("ğŸ“š ê²€ìƒ‰ëœ ì±… ëª©ë¡: \(books.count)ê¶Œ")
                }, onError: { error in
                    print("âš ï¸ ì±… ê²€ìƒ‰ ì‹¤íŒ¨: \(error.localizedDescription)")
                })
        }

        let processBook = { [weak self] (book: BookItem) -> Single<(BookItem, Double)> in
            guard let self else {
                return .never()
            }

            print("ğŸ“· ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘: \(book.image)")

            return apiClient.downloadImage(from: book.image)
                .catch { error in
                    print("âš ï¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: \(error.localizedDescription)")
                    return .error(BookMatchError.imageDownloadFailed)
                }
                .flatMap { downloadedImage in
                    print("ğŸ” ìœ ì‚¬ë„ ë¹„êµ ì‹œì‘")
                    return self.imageStrategy.calculateSimilarity(image, downloadedImage)
                        .map { (book, $0) }
                        .catch { error in
                            print("âš ï¸ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: \(error.localizedDescription)")
                            return .error(
                                BookMatchError
                                    .imageCalculationFailed(error.localizedDescription)
                            )
                        }
                }
        }

        return extractStream
            .flatMap { textData -> Single<[BookItem]> in
                print("ğŸ“Œ matchBook2 ì‹¤í–‰ë¨, OCR ê²°ê³¼: \(textData)")
                return searchBook(textData)
            }
            .flatMap { results -> Single<[BookItem]> in
                print("ğŸ“Œ matchBook3 ì‹¤í–‰ë¨, ê²€ìƒ‰ ê²°ê³¼: \(results.count)ê¶Œ")
                if results.isEmpty {
                    return .error(BookMatchError.noMatchFound)
                }

                return .just(results)
            }
            .flatMap { books in
                print("ğŸ“Œ matchBook4 ì‹¤í–‰ë¨, ìœ ì‚¬ë„ ë¹„êµ ì§„í–‰")
                return Observable.from(books)
                    .flatMap { book in processBook(book).asObservable() }
                    .toArray()
            }
            .map { (results: [(BookItem, Double)]) -> BookItem? in
                print("ğŸ“Œ ìµœì¢… ìœ ì‚¬ë„ ë¹„êµ ì™„ë£Œ: \(results)")
                return results.sorted { $0.1 > $1.1 }.first?.0
            }
            .do(onSuccess: { matchedBook in
                if let book = matchedBook {
                    print("âœ… ìµœì¢… ë§¤ì¹­ëœ ë„ì„œ: \(book.title)")
                } else {
                    print("âš ï¸ ìµœì¢… ë§¤ì¹­ ì‹¤íŒ¨")
                }
            }, onError: { error in
                print("âŒ matchBook ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: \(error.localizedDescription)")
            })
    }

    // MARK: - OCR Logic

    /// ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    /// - Parameter image: í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ì´ë¯¸ì§€
    /// - Returns: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë°°ì—´
    @MainActor
    private func extractText(from image: UIImage) -> Single<[String]> {
        print("ğŸ“Œ extractText ì‹¤í–‰ë¨!") // âœ… OCR ì‹¤í–‰ í™•ì¸

        return Single.create { single in
            Task { @MainActor in // âœ… ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                print("ğŸ“Œ detectBookElements í˜¸ì¶œ ì˜ˆì •") // âœ… ì‹¤í–‰ ì§ì „ í™•ì¸
                self.detectBookElements(in: image) { extractedTexts in
                    print("ğŸ“Œ detectBookElements ê²°ê³¼: \(extractedTexts)") // âœ… OCR ê²°ê³¼ í™•ì¸
                    single(.success(extractedTexts))
                }
            }
            return Disposables.create()
        }
    }

    /// ê°ì§€ëœ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ í™•ì¥í•˜ì—¬ OCR ì •í™•ë„ë¥¼ ë†’ì„
    /// ê°ì§€ëœ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ í™•ì¥í•˜ì—¬ OCR ì •í™•ë„ë¥¼ ë†’ì„
    private func expandBoundingBox(_ boundingBox: CGRect, factor: CGFloat) -> CGRect {
        let x = boundingBox.origin.x - (boundingBox.width * (factor - 1)) / 2
        let y = boundingBox.origin.y - (boundingBox.height * (factor - 1)) / 2
        let width = boundingBox.width * factor
        let height = boundingBox.height * factor

        return CGRect(
            x: max(0, x),
            y: max(0, y),
            width: min(1, width),
            height: min(1, height)
        )
    }

    /// ê°ì§€ëœ ì˜ì—­ì„ í¬ë¡­í•˜ì—¬ OCR ì •í™•ë„ë¥¼ ë†’ì„
    private func cropImage(_ image: UIImage, to boundingBox: CGRect) -> UIImage {
        guard let cgImage = image.cgImage else {
            print("âš ï¸ ì›ë³¸ ì´ë¯¸ì§€ì˜ CGImageë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ, ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜")
            return image
        }
        let width = CGFloat(cgImage.width)
        let height = CGFloat(cgImage.height)

        let cropRect = CGRect(
            x: boundingBox.origin.x * width,
            y: boundingBox.origin.y * height,
            width: boundingBox.width * width,
            height: boundingBox.height * height
        )

        guard let croppedCGImage = cgImage.cropping(to: cropRect) else {
            print("âš ï¸ ì´ë¯¸ì§€ í¬ë¡­ ì‹¤íŒ¨, ì›ë³¸ ì´ë¯¸ì§€ë¡œ OCR ì§„í–‰")
            return image
        }
        return UIImage(cgImage: croppedCGImage)
    }

    /// CoreMLì„ ì‚¬ìš©í•˜ì—¬ ì±… ì œëª©ì„ ì¸ì‹ í›„ OCR ì‹¤í–‰
    @MainActor
    private func detectBookElements(in image: UIImage, completion: @escaping ([String]) -> Void) {
        print("ğŸ“Œ detectBookElements ì‹¤í–‰ë¨!")

        guard let model = try? VNCoreMLModel(for: MyObjectDetector5_1().model) else {
            print("âš ï¸ CoreML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨, OCR ê°•ì œ ì‹¤í–‰")
            performOCR(on: image, completion: completion)
            return
        }

        let request = VNCoreMLRequest(model: model) { request, error in
            if let error {
                print("âš ï¸ Vision ìš”ì²­ ì‹¤íŒ¨: \(error.localizedDescription), OCR ê°•ì œ ì‹¤í–‰")
                self.performOCR(on: image, completion: completion)
                return
            }

            guard let results = request.results as? [VNRecognizedObjectObservation] else {
                print("âš ï¸ Vision ê²°ê³¼ ì—†ìŒ, OCR ê°•ì œ ì‹¤í–‰")
                self.performOCR(on: image, completion: completion)
                return
            }

            // âœ… Confidence Threshold ì™„í™”
            let filteredResults = results.filter { $0.confidence > 0.3 } // ì‹ ë¢°ë„ 30% ì´ìƒ
            if filteredResults.isEmpty {
                print("âš ï¸ ì‹ ë¢°ë„ ë‚®ìŒ, OCR ê°•ì œ ì‹¤í–‰")
                self.performOCR(on: image, completion: completion)
                return
            }

            print("ğŸ“š ê°ì§€ëœ ê°ì²´ ìˆ˜ (Threshold ì ìš©): \(filteredResults.count)")

            var extractedTexts: [String] = []
            let dispatchGroup = DispatchGroup()

            for observation in filteredResults {
                let detectedLabel = observation.labels.first?.identifier ?? "Unknown"
                print("ğŸ” ê°ì§€ëœ ê°ì²´: \(detectedLabel)")

                if detectedLabel == "titles-or-authors" || detectedLabel == "book-title" {
                    dispatchGroup.enter()

                    let expandedBox = self.expandBoundingBox(observation.boundingBox, factor: 1.2)
                    let croppedImage = self.cropImage(image, to: expandedBox) ?? image

                    // âœ… í¬ë¡­ëœ ì´ë¯¸ì§€ ë””ë²„ê¹…ìš©ìœ¼ë¡œ í™•ì¸
                    DispatchQueue.main.async {
                        let debugImageView = UIImageView(image: croppedImage)
                        debugImageView.frame = CGRect(x: 10, y: 100, width: 200, height: 200)
                        debugImageView.contentMode = .scaleAspectFit
                        UIApplication.shared.windows.first?.addSubview(debugImageView)
                    }

                    // âœ… ì›ë³¸ê³¼ í¬ë¡­ëœ ì´ë¯¸ì§€ ëª¨ë‘ OCR ì‹¤í–‰í•˜ì—¬ ë” ì¢‹ì€ ê²°ê³¼ ì„ íƒ
                    self.performOCR(on: croppedImage) { croppedText in
                        self.performOCR(on: image) { originalText in
                            let finalText = croppedText.isEmpty ? originalText : croppedText
                            print("âœ… OCR ì‹¤í–‰ ì™„ë£Œ, ìµœì¢… ê²°ê³¼: \(finalText)")
                            extractedTexts.append(contentsOf: finalText)
                            dispatchGroup.leave()
                        }
                    }
                }
            }

            dispatchGroup.notify(queue: .main) {
                print("ğŸ“‘ ìµœì¢… OCR í…ìŠ¤íŠ¸: \(extractedTexts)")
                if extractedTexts.isEmpty {
                    print("âš ï¸ OCR ì‹¤íŒ¨, ì›ë³¸ ì´ë¯¸ì§€ë¡œ ìµœì¢… OCR ì‹¤í–‰")
                    self.performOCR(on: image, completion: completion)
                } else {
                    completion(extractedTexts)
                }
            }
        }

        do {
            let handler = VNImageRequestHandler(cgImage: image.cgImage!, options: [:])
            try handler.perform([request])
        } catch let error as NSError {
            print("âš ï¸ Vision Request Error: \(error.localizedDescription), OCR ê°•ì œ ì‹¤í–‰")
            performOCR(on: image, completion: completion)
        }
    }

    private func convertToGrayscale(_ image: UIImage) -> UIImage? {
        guard let ciImage = CIImage(image: image) else {
            return nil
        }

        let filter = CIFilter(name: "CIColorControls")
        filter?.setValue(ciImage, forKey: kCIInputImageKey)
        filter?.setValue(1.5, forKey: kCIInputContrastKey) // ëŒ€ë¹„ ì¦ê°€
        filter?.setValue(0.0, forKey: kCIInputSaturationKey) // ì±„ë„ ì œê±° (í‘ë°±)

        guard let outputImage = filter?.outputImage else {
            return nil
        }
        let context = CIContext(options: nil)
        guard let cgImage = context.createCGImage(outputImage, from: outputImage.extent)
        else {
            return nil
        }

        return UIImage(cgImage: cgImage)
    }

    @MainActor
    private func performOCR(on image: UIImage, completion: @escaping ([String]) -> Void) {
        print("ğŸ“Œ performOCR ì‹¤í–‰ë¨!")

        guard let preprocessedImage = convertToGrayscale(image),
              let cgImage = preprocessedImage.cgImage else {
            print("âš ï¸ ëŒ€ë¹„ ì¡°ì • ì‹¤íŒ¨, ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©")
            completion([])
            return
        }

        let request = VNRecognizeTextRequest { request, error in
            if let error {
                print("âš ï¸ OCR ì˜¤ë¥˜ ë°œìƒ: \(error.localizedDescription)")
                completion([])
                return
            }

            guard let observations = request.results as? [VNRecognizedTextObservation],
                  !observations.isEmpty else {
                print("âš ï¸ OCR ê²°ê³¼ ì—†ìŒ")
                completion([])
                return
            }

            let recognizedText = observations.compactMap { $0.topCandidates(1).first?.string }
            print("âœ… OCR ì¸ì‹ëœ í…ìŠ¤íŠ¸: \(recognizedText)")
            completion(recognizedText)
        }

        request.recognitionLanguages = ["ko", "en"]
        request.usesLanguageCorrection = true
        request.minimumTextHeight = 0.005

        Task {
            let resizedImage = await preprocessedImage.resized(toWidth: 1024) ?? preprocessedImage
            print("ğŸ“ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• ì™„ë£Œ: \(resizedImage.size)")

            await MainActor.run {
                let requestHandler = VNImageRequestHandler(
                    cgImage: resizedImage.cgImage!,
                    options: [:]
                )
                do {
                    print("ğŸ“ OCR ì‹¤í–‰ ì¤‘...")
                    try requestHandler.perform([request])
                } catch {
                    print("âš ï¸ OCR ìš”ì²­ ì‹¤íŒ¨: \(error.localizedDescription)")
                    completion([])
                }
            }
        }
    }

    /// `OCRë¡œ ê²€ì¶œëœ í…ìŠ¤íŠ¸ ë°°ì—´`ë¡œ ë„ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    /// - Note:``matchBook(_:, image:)`` ë©”ì„œë“œì— ì‚¬ìš©ë©ë‹ˆë‹¤.
    ///
    /// - Parameters:
    ///   - sourceBook: ê²€ìƒ‰í•  ë„ì„œì˜ ê¸°ë³¸ ì •ë³´
    /// - Returns: ê²€ìƒ‰ëœ ë„ì„œ ëª©ë¡
    /// - Throws: BookMatchError
    private func fetchSearchResults(from textData: [String]) -> Single<[BookItem]> {
        guard !textData.isEmpty else {
            return .just([])
        }

        return Single<[BookItem]>.create { single in
            var searchResults = [BookItem]()
            var previousResults = [BookItem]()
            var currentIndex = 0
            var currentQuery = ""

            func processNextQuery() {
                guard currentIndex < textData.count else {
                    single(.success(searchResults))
                    return
                }

                if currentQuery.isEmpty {
                    currentQuery = textData[currentIndex]
                } else {
                    currentQuery = [currentQuery, textData[currentIndex]].joined(separator: " ")
                }

                Single<Void>.just(())
                    .delay(
                        .milliseconds(500),
                        scheduler: ConcurrentDispatchQueueScheduler(qos: .background)
                    )
                    .flatMap { [weak self] _ -> Single<[BookItem]> in
                        guard let self else {
                            return .error(BookMatchError.noMatchFound)
                        }
                        return apiClient.searchBooks(query: currentQuery, limit: 10)
                    }
                    .subscribe(
                        onSuccess: { results in
                            if !results.isEmpty {
                                previousResults = results
                            }
                            if results.count <= 3 {
                                searchResults = previousResults
                                single(.success(searchResults))
                            } else if currentIndex == textData.count - 1 {
                                searchResults = results.isEmpty ? previousResults : results
                                single(.success(searchResults))
                            } else {
                                currentIndex += 1
                                processNextQuery()
                            }
                        }, onFailure: { error in
                            single(.failure(error))
                        }
                    )
                    .disposed(by: self.disposeBag)
            }

            processNextQuery()

            return Disposables.create()
        }
    }
}
